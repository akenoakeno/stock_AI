{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d786fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Policy_Agent import ActorCritic\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "import math\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98d427b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkDataSet(data_size, data_length=50, freq=60.):\n",
    "    train_x = []\n",
    "    train_t = []\n",
    "\n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[math.sin(2*math.pi*(offset+i)/freq)+np.random.normal(loc=0.0, scale=0.015)] for i in range(data_length)])\n",
    "        train_t.append([math.sin(2*math.pi*(offset+data_length)/freq)])\n",
    "\n",
    "    return train_x, train_t #train_x=(data_size, data_length, 1), train_t=(data_size, 1)\n",
    "\n",
    "training_size = 500\n",
    "data_length=50\n",
    "epoch_num = 100\n",
    "hidden_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cb1b03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d0b4882",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ActorCritic(data_length, device)\n",
    "reward_history = []\n",
    "loss_pi_history = []\n",
    "loss_v_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50aeae89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.164439817129412 0.8738823785406566 tensor([0.5137])\n",
      "1 0.8716311198060396 0.2316014367970638 tensor([1.4707])\n",
      "2 0.8952502487953033 0.3747714642668143 tensor([1.2409])\n",
      "3 0.9795194690981397 0.9910590088256868 tensor([1.3737])\n",
      "4 0.8893827543793984 -1.2356137996248435 tensor([-0.6891])\n",
      "5 1.0569491609995616 0.7355725899687968 tensor([0.9184])\n",
      "6 0.9095665840411309 -0.6788822570679258 tensor([0.5156])\n",
      "7 0.9288165920233098 1.2398696361051407 tensor([1.0107])\n",
      "8 0.8503467613261293 0.02837352576898411 tensor([1.8958])\n",
      "9 0.8995096144229067 0.17019108691965812 tensor([1.5941])\n",
      "10 1.0237795188751733 -1.224956468315213 tensor([-0.3448])\n",
      "11 0.8898369985256844 1.1255795018005301 tensor([1.3127])\n",
      "12 0.9096530876513294 -0.47070199668542045 tensor([1.2482])\n",
      "13 0.8693797200375943 -0.05434943099680822 tensor([0.3736])\n",
      "14 0.9049937016523728 0.23871739843161777 tensor([1.1052])\n",
      "15 0.8996834759305123 0.8016598404501565 tensor([1.9596])\n",
      "16 0.9284801492929873 -0.44345974349198514 tensor([1.0649])\n",
      "17 0.911192240091431 0.18798754553790786 tensor([1.2824])\n",
      "18 0.8838071894587429 -0.2830595095001627 tensor([0.7844])\n",
      "19 0.862692902973766 -0.4685405706841266 tensor([0.3148])\n",
      "20 0.9988541206532808 -0.3521650957118254 tensor([0.4777])\n",
      "21 1.0529684535787833 -0.39867810769646894 tensor([-0.0564])\n",
      "22 0.9157924632887751 0.6547570734037436 tensor([1.2337])\n",
      "23 0.9284933106107047 -0.9162241724552587 tensor([-0.0748])\n",
      "24 0.9248875488046986 1.0080710187612567 tensor([2.1251])\n",
      "25 0.9225077293433843 0.5107171660347376 tensor([1.7757])\n",
      "26 0.9284152950782536 -0.0910677617212059 tensor([1.1102])\n",
      "27 0.9599273765276131 0.1688343708665343 tensor([0.2679])\n",
      "28 0.9351403810689476 0.5667318826745031 tensor([1.6211])\n",
      "29 0.9278986396634823 -0.3273145140738052 tensor([0.7288])\n",
      "30 0.9377399579389945 -0.3691682403732557 tensor([0.4385])\n",
      "31 0.8692466501072842 0.5053670736961067 tensor([1.6695])\n",
      "32 0.9960666656642516 0.622682123519553 tensor([0.7995])\n",
      "33 0.8416004976651372 -0.37595376675744774 tensor([0.6264])\n",
      "34 0.8973028223672124 0.29118482739249885 tensor([1.4113])\n",
      "35 0.8786954732084489 -0.4215846037113806 tensor([0.5570])\n",
      "36 0.8993355568508301 -1.095895921727788 tensor([-0.0219])\n",
      "37 0.9678102800047554 1.7727685042482335 tensor([1.7507])\n",
      "38 0.8824524384541093 -0.6829946905781981 tensor([0.1366])\n",
      "39 0.8330190088190115 0.33109292555309366 tensor([0.8289])\n",
      "40 0.8787118825251845 0.3604645601590164 tensor([0.6034])\n",
      "41 2.3349477809871217 2.266142456268426 tensor([1.1910])\n",
      "42 1.438279054231872 0.6598264410422416 tensor([0.2855])\n",
      "43 1.3467453961666118 1.6346224043954862 tensor([2.2347])\n",
      "44 1.0132478090686838 0.22303887502494035 tensor([1.1237])\n",
      "45 0.9666921834545512 -0.6464591262047179 tensor([1.0713])\n",
      "46 1.1420530434496072 0.4594671385202673 tensor([1.0097])\n",
      "47 1.5278480281547369 -0.8031410172698088 tensor([1.5216])\n",
      "48 0.6983812838071595 0.3341707968938863 tensor([0.4180])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     reward \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0.\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m loss_v, loss_pi \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mupdate(state, torch\u001b[38;5;241m.\u001b[39mclip(probs, \u001b[38;5;241m1e-8\u001b[39m, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1e-8\u001b[39m), reward\u001b[38;5;241m.\u001b[39mclone(), next_state)\n\u001b[1;32m     21\u001b[0m total_loss_v \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_v\n\u001b[1;32m     22\u001b[0m total_loss_pi \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_pi\n",
      "File \u001b[0;32m~/Documents/stock_agent/Policy_Agent.py:40\u001b[0m, in \u001b[0;36mActorCritic.update\u001b[0;34m(self, state, action_probs, reward, next_state)\u001b[0m\n\u001b[1;32m     37\u001b[0m loss_pi \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlog(action_probs) \u001b[38;5;241m*\u001b[39m delta)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 40\u001b[0m \u001b[43mloss_v\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_v\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpi\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:352\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    345\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    346\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    351\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 352\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_num):\n",
    "    total_reward = 0\n",
    "    total_loss_pi = 0\n",
    "    total_loss_v = 0\n",
    "    train_x, train_t = mkDataSet(training_size)\n",
    "    for ep in range(training_size-1):\n",
    "        state = torch.tensor([train_x[ep]]).to(device)\n",
    "        done = False\n",
    "\n",
    "        action, probs = agent.get_action(state)\n",
    "        next_state = torch.tensor([train_x[ep+1]]).to(device)\n",
    "\n",
    "        if action == 0:\n",
    "            reward = next_state[0][-1] - state[0][-1]\n",
    "        else:\n",
    "            reward = torch.tensor([0.]).to(device)\n",
    "\n",
    "        total_reward += reward.to('cpu')\n",
    "\n",
    "        loss_v, loss_pi = agent.update(state, torch.clip(probs, 1e-8, 1-1e-8), reward.clone(), next_state)\n",
    "        total_loss_v += loss_v\n",
    "        total_loss_pi += loss_pi\n",
    "\n",
    "        state = next_state\n",
    "        \n",
    "    loss_v_history.append(total_loss_v)\n",
    "    loss_pi_history.append(total_loss_pi)\n",
    "    reward_history.append(total_reward)\n",
    "\n",
    "#    if epoch % 10 ==0:\n",
    "    print(epoch, total_loss_v, total_loss_pi, total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d955223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(np.array(reward_history), color = \"r\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(np.array(loss_pi_history), color = \"r\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(np.array(loss_v_history), color = \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c6502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
